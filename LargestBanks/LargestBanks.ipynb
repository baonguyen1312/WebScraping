{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = 'code_log.txt'\n",
    "url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "attribute_list = ['Name', 'MC_USD_Billion']\n",
    "csv_path = 'Largest_banks.csv'\n",
    "database_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%m:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(timestamp + \": \" + message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, attributes):\n",
    "    df = pd.DataFrame(columns=attributes)\n",
    "    html_page = requests.get(url).text\n",
    "    data = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[0].find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col) != 0:\n",
    "            data_dict = {\n",
    "                'Name': col[1].find_all('a')[1].get('title'),\n",
    "                'MC_USD_Billion': float(col[2].contents[0].split(\"\\n\")[0])\n",
    "            }\n",
    "\n",
    "            new_df = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df_copied = df.copy()\n",
    "    df_copied['MC_EUR_Billion'] = np.round(df['MC_USD_Billion'] * 0.92, 2)\n",
    "    df_copied['MC_GBP_Billion'] = np.round(df['MC_USD_Billion'] * 0.77, 2)\n",
    "    df_copied['MC_INR_Billion'] = np.round(df['MC_USD_Billion'] * 84.08, 2)\n",
    "\n",
    "    return df_copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "def load_to_db(df, table_name, connect):\n",
    "    df.to_sql(table_name, connect, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, connect):\n",
    "    output_query = pd.read_sql(query, connect)\n",
    "    print(query)\n",
    "    print(output_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_EUR_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          398.29   \n",
      "1                          Bank of America          231.52          213.00   \n",
      "2  Industrial and Commercial Bank of China          194.56          179.00   \n",
      "3               Agricultural Bank of China          160.68          147.83   \n",
      "4                                HDFC Bank          157.91          145.28   \n",
      "5                              Wells Fargo          155.87          143.40   \n",
      "6                                     HSBC          148.90          136.99   \n",
      "7                           Morgan Stanley          140.83          129.56   \n",
      "8                  China Construction Bank          139.82          128.63   \n",
      "9                            Bank of China          136.81          125.87   \n",
      "\n",
      "   MC_GBP_Billion  MC_INR_Billion  \n",
      "0          333.35        36399.91  \n",
      "1          178.27        19466.20  \n",
      "2          149.81        16358.60  \n",
      "3          123.72        13509.97  \n",
      "4          121.59        13277.07  \n",
      "5          120.02        13105.55  \n",
      "6          114.65        12519.51  \n",
      "7          108.44        11840.99  \n",
      "8          107.66        11756.07  \n",
      "9          105.34        11502.98  \n",
      "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
      "   AVG(MC_GBP_Billion)\n",
      "0              146.285\n",
      "SELECT Name from Largest_banks LIMIT 5\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oab13\\AppData\\Local\\Temp\\ipykernel_6848\\130418045.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Start Project\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating extract data.')\n",
    "\n",
    "df = extract(url, attribute_list)\n",
    "log_progress('Extraction complete. Initiating transform data.')\n",
    "\n",
    "transformed_df = transform(df)\n",
    "log_progress('Transformation complete. Initiating load to csv.')\n",
    "\n",
    "load_to_csv(transformed_df, csv_path)\n",
    "log_progress('Load to csv complete. Initiating load to database.')\n",
    "\n",
    "conn = sqlite3.connect(database_name)\n",
    "log_progress('SQL Connection initiated')\n",
    "\n",
    "load_to_db(transformed_df, table_name, conn)\n",
    "log_progress('Load to database complete. Intiating query.')\n",
    "\n",
    "\n",
    "query_statements = [\n",
    "    'SELECT * FROM Largest_banks',\n",
    "    'SELECT AVG(MC_GBP_Billion) FROM Largest_banks',\n",
    "    'SELECT Name from Largest_banks LIMIT 5'\n",
    "]\n",
    "for sql in query_statements:\n",
    "  run_query(sql, conn)\n",
    "log_progress('Process Complete')\n",
    "\n",
    "conn.close()\n",
    "log_progress('Server Connection closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
